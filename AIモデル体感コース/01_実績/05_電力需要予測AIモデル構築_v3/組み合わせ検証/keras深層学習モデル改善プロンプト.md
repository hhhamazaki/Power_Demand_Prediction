
日曜日に全モデル予測が大きく実績との乖離が大きい原因を究明し修正
曜日、土日、祝日、連休など要素を解析、予測と実績の乖離が大きい原因を究明し修正

---

AI\train\モデル\モデル_train.py
AI\tomorrow\モデル\モデル_tomorrow.py
AI\server.py、AI\dashboard\index.html操作にAI_TARGET_YEARS機能が必要

---

全モデル精度の順位を表示

全モデル高精度3年（2年学習1年テスト）組み合わせ限定
AI\server.pyから組み合わせ検証ボタン実行
AI\server.log各モデル処理時間解析

現在（2025年）予測AI\tomorrow\モデル\モデル_tomorrow.pyに最適な組み合わせ学習年を検証し推奨するAI\train\モデル\モデル_optimize_years.py作成
各モデル結果を、AI\train\モデル\yy-MM-dd_モデル_optimize_years.txtとして、各モデル用フォルダに保存、メモ帳で開く

ダッシュボードの学習カード学習ボタンと同じ様式で、学習年カードに「組み合わせ検証」ボタン追加
ツールチップ位置ボタン被らない少し上（学習ボタンと同じ様式）

---

実際に動作を検証、悪化したら修正を繰り返せ！
実際に動作を検証せずレポートするな！
AI\tomorrow\Keras\Keras_tomorrow.pyへの影響も考慮

keras深層学習モデル精度が、最高LightGBM（RMSE: 152.582 kW）比較し大幅に悪化
設計上の問題を究明し修正、Keras過学習対策、正則化バランス、Batch、Dropout、学習率を調整
学習3年（2022,2023,2024）対象
複数の設定パターンを追加したり削除したり変更したりして、動作の検証を徹底的に何度も繰り返し、最適な構成を実験的に決定

---

# 結論

- 学習履歴では訓練損失は検証の変動（val_mae の上下）が大きく、汎化の限界。
- これまでの実験で分かっている重要点：
    - y_scaler は必須（以前これが外れたため大劣化）。
    - Dropout・バッチ・LR の微調整で結果が敏感に変わる（過学習と汎化のトレードオフ）。
- 単一モデルの微調整だけでは LightGBM のベースライン差（約16 kW）を埋められない可能性が高い。

---
