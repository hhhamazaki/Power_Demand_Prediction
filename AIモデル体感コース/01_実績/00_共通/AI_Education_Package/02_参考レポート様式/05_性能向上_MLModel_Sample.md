# ⑤ 性能向上：MLモデル 性能比較レポート（Sample）

## 1. 基本情報
- 受講者氏名：田中 太郎
- 作成日：2025年10月1日
- 対象工程：⑤ 性能向上（MLモデル最適化・性能比較）
- 比較対象条件：
  - 条件A：Keras深層ニューラルネットワークモデル（TensorFlow 2.15.0基盤）
  - 条件B：LightGBM勾配ブースティングモデル（LightGBM 3.3.5）
  - 条件C：PyCaret自動機械学習モデル（PyCaret 3.0.0 + RandomForest）
  - 条件D：RandomForestアンサンブルモデル（scikit-learn 1.2.2）

---

## 2. 実験概要
- 実験目的：電力需要予測における4つの機械学習アルゴリズムの性能比較評価により最適モデルを選定し、電力供給計画の精度向上を図る
- 比較観点：
  - 実行時間（秒）：モデル学習完了までの総処理時間
  - メモリ使用量（GB）：学習時最大メモリ消費量
  - 予測精度（%）：RMSE基準での電力需要予測精度
  - R2スコア：決定係数による予測精度評価指標
- 使用データセット：東京電力管内電力需要実績データ（2016-2025年）+ 気象庁気温データ
- 実行環境（OS / CPU / GPU / メモリ / ツール / バージョン）：Windows 11 / Intel Core i7-12700H / なし / 16GB / VS Code / Python 3.10.11
- 実行回数：各モデル3回実行による平均値算出
- 計測方法：
  - 実行時間：robust_model_operationデコレータによる処理開始から終了までの経過時間を計測
  - メモリ使用量：psutil.virtual_memory()による学習時最大メモリ使用率を計測
  - 予測精度：RMSE値から算出した予測精度パーセンテージ（100 - RMSE/平均需要量*100）
  - R2スコア：scikit-learnの`r2_score`関数による決定係数を算出
- 許容基準値：実行時間300秒以内、メモリ使用量8GB以内、予測精度95%以上、R2スコア0.90以上

---

## 3. 実験結果

| 比較条件 | 実行時間（秒） | メモリ使用量（GB） | 予測精度（%） | R2スコア | 備考 |
|----------|----------------|--------------------|--------------|---------|------|
| 条件A（Keras） | 285.3 | 6.8 | 96.2 | 0.9031 | EarlyStopping有効、学習曲線可視化 |
| 条件B（LightGBM） | 42.7 | 2.1 | 97.1 | 0.9156 | 並列処理最適化、高速学習達成 |
| 条件C（PyCaret） | 156.8 | 4.3 | 96.8 | 0.9089 | AutoML自動最適化、安定性重視 |
| 条件D（RandomForest） | 78.4 | 3.2 | 96.5 | 0.9067 | アンサンブル効果、バランス型 |

---

## 4. 考察
- 実行時間短縮の要因：LightGBMの並列処理最適化（n_jobs=-1）により全CPU活用が実現され、従来比60%の時間短縮を達成。勾配ブースティングアルゴリズムの効率的な実装により高速学習が可能
- メモリ使用量削減の要因：float32データ型採用による50%メモリ削減効果、LightGBMの内部メモリ最適化機能、ガベージコレクション自動実行によるメモリリーク防止
- 予測精度維持の要因：時系列特徴量エンジニアリング（MONTH・WEEK・HOUR・TEMP）の効果、StandardScaler正規化による学習安定性向上、各アルゴリズムの特性を活かした最適化
- R2スコア維持の要因：4モデル全てで目標値0.90を上回る結果を達成。特にLightGBMは0.9156と最高スコアを記録し、勾配ブースティングの優位性を実証
- 改善が見られた点：メモリ使用量の大幅削減（従来比50%減）、処理速度の向上（LightGBM：60%短縮）、予測精度の安定化（全モデル95%以上）、統一アーキテクチャによる保守性向上
- 劣化が見られた点：Kerasモデルの学習時間が他モデルより長時間（285秒）、深層学習特有の計算コスト、ハイパーパラメータ調整の複雜性
- 想定外の結果や原因：PyCaret AutoMLの予測精度がRandomForestを上回る結果（96.8% vs 96.5%）。自動特徴量選択・ハイパーパラメータ最適化の効果が手動調整を上回った

---

## 5. 結論
- 最適条件の選定理由：LightGBM（条件B）を最適解として選定。理由：①最高予測精度97.1%達成、②最短実行時間42.7秒、③最小メモリ使用量2.1GB、④最高R2スコア0.9156、⑤並列処理による拡張性、⑥運用コスト最小化
- 今後の改善案：①4モデルアンサンブル予測による精度向上検討、②GPU活用によるKeras高速化、③リアルタイム予測API化、④自動再学習機能実装、⑤概念ドリフト検出機能追加
- 他工程への適用可能性：①関西電力・中部電力等の地域拡張、②ガス需要・水道需要予測への転用、③製造業の需要予測システムへの応用、④小売業の売上予測システムへの展開、⑤交通量予測システムへの活用

---

## 6. 再現手順
1. 実験用データセットの準備：`python .\data\data.py`により電力需要・気温データ統合処理実行、Xtrain.csv・Ytrain.csv生成確認
2. 条件A/B/C/Dの環境構築：仮想環境作成後`pip install -r requirements.txt`により28パッケージ一括インストール、Python 3.10.11環境確認
3. 各条件での性能測定（実行時間・メモリ使用量）：robust_model_operationデコレータによる自動計測、psutil.virtual_memory()でメモリ監視
4. 精度評価（予測精度・R2スコア）：テストデータ（10%分割）でのRMSE・R2スコア算出、scikit-learn評価指標活用
5. 結果集計と分析：CSV形式予測結果保存、16:9アスペクト比PNG可視化、性能指標の統計分析実施

---

## 7. 添付・参考資料
- 添付ファイル名：Keras_Ypred.png（学習結果可視化）、LightGBM_Ypred.png（予測結果グラフ）、PyCaret_model_comparison.png（モデル比較表）、RandomForest_feature_importance.png（特徴量重要度）
- 参考URLや文献：TensorFlow公式ドキュメント、LightGBM Performance Guide、PyCaret AutoML Tutorial、scikit-learn RandomForest Documentation